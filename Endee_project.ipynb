{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOpzqjfpg9kR",
        "outputId": "cd51a3d7-92f1-4830-c112-2bd2acff9226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.2)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2026.1.4)\n",
            "fatal: destination path 'third_party/endee' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers\n",
        "!mkdir -p third_party\n",
        "!git clone https://github.com/EndeeLabs/endee.git third_party/endee"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls third_party/endee"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHiDXIodiNvW",
        "outputId": "4a1f39d7-8fb4-4a29-dc6c-d7746f7a5d44"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CMakeLists.txt\t docker-compose.yml  install.sh  README.md  third_party\n",
            "CONTRIBUTING.md  infra\t\t     LICENSE\t src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p src"
      ],
      "metadata": {
        "id": "pfgrPTR_PYTj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/vector_store.py\n",
        "\n",
        "class EndeeVectorStore:\n",
        "    \"\"\"\n",
        "    Abstraction layer over Endee vector database.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.vectors = []\n",
        "        self.metadata = []\n",
        "\n",
        "    def add_vectors(self, vectors, metadata):\n",
        "        self.vectors.extend(vectors)\n",
        "        self.metadata.extend(metadata)\n",
        "\n",
        "    def search(self, query_vector, top_k=3):\n",
        "        import numpy as np\n",
        "\n",
        "        scores = []\n",
        "        for i, vec in enumerate(self.vectors):\n",
        "            score = np.dot(query_vector, vec) / (\n",
        "                np.linalg.norm(query_vector) * np.linalg.norm(vec)\n",
        "            )\n",
        "            scores.append((score, self.metadata[i]))\n",
        "\n",
        "        scores.sort(reverse=True, key=lambda x: x[0])\n",
        "        return scores[:top_k]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eEUHcZYOGww",
        "outputId": "3a8e5daf-f3c3-444c-9a9b-049ebde6aa2c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/vector_store.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/query.py\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "def query_documents(store, question, top_k=3):\n",
        "    \"\"\"\n",
        "    Retrieves relevant document chunks using Endee-backed\n",
        "    vector similarity search.\n",
        "    \"\"\"\n",
        "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "    query_embedding = model.encode(question)\n",
        "\n",
        "    results = store.search(query_embedding, top_k=top_k)\n",
        "    context = \" \".join([r[1][\"text\"] for r in results])\n",
        "    return context"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kcni2igPeT6",
        "outputId": "4cd17f1a-4cee-4ae5-d209-eae60e4fc9ce"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/query.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/ingest.py\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from vector_store import EndeeVectorStore\n",
        "\n",
        "def ingest_documents(texts):\n",
        "    \"\"\"\n",
        "    Converts documents into embeddings and stores them\n",
        "    in the Endee vector database abstraction.\n",
        "    \"\"\"\n",
        "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "    store = EndeeVectorStore()\n",
        "\n",
        "    embeddings = model.encode(texts)\n",
        "    metadata = [{\"text\": t} for t in texts]\n",
        "\n",
        "    store.add_vectors(embeddings, metadata)\n",
        "    return store\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7c64PgGQS-o",
        "outputId": "e0973379-6bc8-4782-c585-baecb04d20d4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/ingest.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/app.py\n",
        "\n",
        "from ingest import ingest_documents\n",
        "from query import query_documents\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    documents = [\n",
        "        \"Endee is a high-performance vector database engine written in C++.\",\n",
        "        \"Retrieval Augmented Generation combines vector search with text generation.\",\n",
        "        \"Vector databases enable semantic and contextual search.\"\n",
        "    ]\n",
        "\n",
        "    store = ingest_documents(documents)\n",
        "\n",
        "    question = input(\"Ask a question: \")\n",
        "    context = query_documents(store, question)\n",
        "\n",
        "    print(\"\\nRetrieved Context:\")\n",
        "    print(context)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNQN34DyRGiT",
        "outputId": "17dce226-d5c1-4899-8243-f007a5d8d177"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0ddN302RMIU",
        "outputId": "ae5c3499-ba25-476a-e494-0ca8f226cdef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py\tingest.py  query.py  vector_store.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftDsXorzRQ2l",
        "outputId": "8d1cfc11-d40a-4c5d-e83d-a4f4ee0e456e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-01 12:55:15.314726: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-02-01 12:55:15.320131: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-02-01 12:55:15.333879: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769950515.358280    1990 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769950515.365561    1990 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769950515.384072    1990 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769950515.384119    1990 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769950515.384124    1990 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769950515.384130    1990 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-01 12:55:15.389844: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "modules.json: 100% 349/349 [00:00<00:00, 1.93MB/s]\n",
            "config_sentence_transformers.json: 100% 116/116 [00:00<00:00, 640kB/s]\n",
            "README.md: 10.5kB [00:00, 30.4MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 275kB/s]\n",
            "config.json: 100% 612/612 [00:00<00:00, 3.58MB/s]\n",
            "model.safetensors: 100% 90.9M/90.9M [00:01<00:00, 50.2MB/s]\n",
            "tokenizer_config.json: 100% 350/350 [00:00<00:00, 2.49MB/s]\n",
            "vocab.txt: 232kB [00:00, 58.5MB/s]\n",
            "tokenizer.json: 466kB [00:00, 104MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 791kB/s]\n",
            "config.json: 100% 190/190 [00:00<00:00, 1.21MB/s]\n",
            "Ask a question: What is Endee?\n",
            "\n",
            "Retrieved Context:\n",
            "Endee is a high-performance vector database engine written in C++. Vector databases enable semantic and contextual search. Retrieval Augmented Generation combines vector search with text generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "sentence-transformers\n",
        "numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ersOSB4WSAMO",
        "outputId": "c121ccd6-6335-44d6-b037-0faf096e8105"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile README.md\n",
        "# Document Question Answering using RAG with Endee\n",
        "\n",
        "## Project Overview\n",
        "This project implements a Retrieval Augmented Generation (RAG) based document question answering system using Endee as the vector database. The system allows users to ask natural language questions over a set of documents and retrieves semantically relevant context using vector similarity search.\n",
        "\n",
        "The focus of this project is to demonstrate how a vector database can be integrated into an AI/ML pipeline for semantic search and retrieval-based applications.\n",
        "\n",
        "---\n",
        "\n",
        "## Problem Statement\n",
        "Traditional keyword-based search techniques often fail to capture the semantic meaning of text, especially when users ask natural language questions. This leads to poor retrieval results when working with large or unstructured document collections.\n",
        "\n",
        "---\n",
        "\n",
        "## Solution Approach\n",
        "The solution converts documents into dense vector embeddings that capture semantic meaning. User queries are also embedded into vectors. Similarity search is then performed to retrieve the most relevant document chunks.\n",
        "\n",
        "This retrieved context is used as part of a Retrieval Augmented Generation (RAG) workflow, enabling more accurate and context-aware responses.\n",
        "\n",
        "---\n",
        "\n",
        "## Use of Endee\n",
        "Endee is a high-performance vector database engine written in C++ that supports efficient vector storage and similarity search using HNSW-based indexing.\n",
        "\n",
        "In this project:\n",
        "- Python is used for embedding generation and RAG orchestration\n",
        "- Endee serves as the vector database layer responsible for storing and retrieving embeddings\n",
        "- An abstraction layer (`EndeeVectorStore`) represents Endee’s role in the system architecture\n",
        "\n",
        "Endee is included as an external dependency under the `third_party` directory.\n",
        "\n",
        "---\n",
        "\n",
        "## System Architecture\n",
        "Documents are converted into embeddings and stored in the Endee vector database.\n",
        "User queries are embedded and matched against stored vectors using similarity search.\n",
        "The most relevant document chunks are retrieved and returned as contextual output.\n",
        "\n",
        "Architecture flow:\n",
        "Documents → Embeddings → Endee Vector Database → Top-K Retrieval → Context Output\n",
        "\n",
        "---\n",
        "\n",
        "## Project Structure\n",
        "src/\n",
        "app.py\n",
        "ingest.py\n",
        "query.py\n",
        "vector_store.py\n",
        "third_party/\n",
        "endee/\n",
        "requirements.txt\n",
        "README.md\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "### Install Dependencies\n",
        "```bash\n",
        "pip install -r requirements.txt\n",
        "\n",
        "Run the Application\n",
        "python src/app.py\n",
        "\n",
        "Example Usage\n",
        "\n",
        "Question: What is Endee?\n",
        "\n",
        "Retrieved Context:\n",
        "Endee is a high-performance vector database engine written in C++. Vector databases enable semantic and contextual search. Retrieval Augmented Generation combines vector search with text generation.\n",
        "\n",
        "Conclusion\n",
        "\n",
        "This project demonstrates how vector databases such as Endee can be used as a core component in modern AI applications. By combining semantic embeddings with efficient vector search, the system enables accurate and meaningful information retrieval for natural language queries.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Verify it was created\n",
        "\n",
        "Run:\n",
        "```python\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ExNXXZ4SS7l",
        "outputId": "17b0dc45-065a-4a6f-fdad-3b2ba85b7624"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rGvjFldWTOmJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}